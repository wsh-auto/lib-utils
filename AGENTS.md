================================================================
User Provided Header
================================================================
<!-- User Provided Header -->
AGENTS context for lib-utils

PRIMARY: SKILL.md (1.6k) - How to use; self-contained

## Other Documentation
- @CONTRIBUTING.md (600) - How to develop/maintain
- @package.json (300) - Dependencies, scripts, project metadata

All other files below are supporting context from dependencies.

Generated by rp: 3 skills, 4 files, 9 @ refs

---

Per https://developers.openai.com/codex/cloud/code-review/, when reviewing code in Github PR, Codex searches for closest AGENTS.md h2 "## Review Guidelines". Ignore the "## Review Guidelines" section if you are not in code review mode.

## Review Guidelines
@codex review this codebase. Consider your review the final review before this Pull Request (PR) is merged, so do a final comprehensive review.

Review process:
1. Read this file (AGENTS.md). It contains all project documentation and requiredSkills and requiredFiles inlined using repomix.
2. Identify ALL issues across the entire codebase.
  - Verify implementation matches spec (compare file timestamps if docs and code disagree to determine which should be considered canonical)
3. Post ALL issues found.
  - **CRITICAL:** End every response/review/inline comment with the commit SHA being reviewed (**{commitSha}**) for thread tracking
  - **CRITICAL:** Do NOT stop after finding one issue. Report all issues of all severities in one go.

================================================================
Files
================================================================

================
File: edit-skill/SKILL.md
================
---
name: edit-skill
description: >-
  Guide for editing and creating Skills. This skill should be used when users want to edit an existing Skill or create a new Skill that extends agentic capabilities with specialized knowledge, workflows, or tool integrations.
source: ~/mnt/data/mirrors/openai/skills/skills/.system/skill-creator/
hackmd: https://hackmd.io/TmfBsoskTnGqEf90YZch5Q
---

# Skill Editor and Builder

## TABLE OF CONTENTS
1. REQUIRED READING
  - If creating a New Skill
  - If creating/editing a "query-" skill (API integration), MUST also read:
  - If creating/editing an "audit-" skill (quality validation), MUST also read:
2. About Skills
  - Naming Skills
  - Anatomy of a Skill
  - Progressive Disclosure Design Principle
3. YAML Metadata
  - name: and description:
  - host:
4. Bundled Resources Details
  - scripts/
  - references/
  - assets/
5. Process for Editing Skills
  - Understanding Existing Structure
  - Making Effective Edits
  - Generate CLAUDE.md
  - Validation Workflow
  - Testing Script Changes
  - Audit with `$mdr:audit-skill`
6. $edit-skill Scripts
  - ccsync

## REQUIRED READING
**MUST read immediately if conditions met.**

### If creating a New Skill
- `references/creating-new-skills.md`

#### Skill Creation Process
1. Understand concrete use cases
2. Plan reusable resources
3. Create skill directory with SKILL.md (use YAML template from "YAML Metadata" section)
4. Edit the skill (see editing process above)
5. Package skill (_EDIT-SKILL_package, globally available)
6. Iterate

Do NOT attempt to edit or create skills without reading these files first. They contain critical workflows, validation steps, and guidelines that cannot be skipped.

### If creating/editing a "query-" skill (API integration), MUST also read:
- `references/special-instructions-use-skills.md`

### If creating/editing an "audit-" skill (quality validation), MUST also read:
- `references/special-instructions-audit-skills.md`

## About Skills
Skills are modular, self-contained packages that extend Claude's capabilities by providing specialized knowledge, workflows, and tools. Think of them as "onboarding guides" for specific domains or tasks—they transform Claude from a general-purpose agent into a specialized agent equipped with procedural knowledge that no model can fully possess.

**What Skills Provide**
1. Specialized workflows - Multi-step procedures for specific domains
2. Tool integrations - Instructions for working with specific file formats or APIs
3. Domain expertise - Company-specific knowledge, schemas, business logic
4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks

### Naming Skills
All skills must follow the naming conventions in ../CONTRIBUTING.md. Key prefixes:
- **id-***: Personal lifestyle/hobby domains with complex workflows (e.g., id-shopper, id-cocktails, id-japanese, id-travel)
- **topic-***: Domain-specific knowledge (e.g., topic-health, topic-books)
- **format-***: Output formatting (e.g., format-json, format-markdown-tables)
- **persona-***: Professional role expertise (e.g., persona-architect, persona-test-engineer)
- **edit-***: Create/edit specific file types (e.g., edit-skill, edit-claude-subagent)
- **task-***: Conversational output workflows (e.g., task-classify-conversation)
- **workflow-***: Multi-step file creation workflows (e.g., workflow-project)
- **query-***: External service/API interaction (e.g., query-airtable, query-hackmd)
- **dev-***: Development tooling & workflows (e.g., dev-mcp-server)
- **ops-***: Operations & infrastructure tools (e.g., ops-git, ops-pm2)
- **test-***: Testing tools & workflows (e.g., test-mcp-server, test-playwright)
- **interface-***: ChatGPT.com customization (e.g., interface-chatgpt-memory)

### Anatomy of a Skill
Every skill consists of a required SKILL.md file and optional bundled resources:

```
skill-name/
├── SKILL.md (required)
│   ├── YAML frontmatter metadata (required)
│   │   ├── name: (required)
│   │   └── description: (required)
│   └── Markdown instructions (required)
└── Bundled Resources (optional)
    ├── scripts/          - Executable code (Python/Bash/etc.)
    ├── references/       - Documentation loaded into context as needed
    └── assets/           - Files used in output (templates, icons, fonts)
```

### Progressive Disclosure Design Principle
Skills use a three-level loading system to manage context efficiently:

1. **Metadata (name + description)** - Always in context (~100 words)
2. **SKILL.md body** - When skill triggers (<5k words)
3. **Bundled resources** - As needed by Claude (Unlimited*)

*Unlimited because scripts can be executed without reading into context window.

## YAML Metadata
### name: and description:
`name:`** and **`description:`** determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. "This skill should be used when..." instead of "Use this skill when..."). For description, use `>-` folded block scalar with content on single line (no 80-char wrapping).

### host:
**`host:`** - Specify when a skill must run on a specific machine (e.g., browser automation, apps only installed there):
- On target host → run commands directly
- On different host → `ssh <host> "cd <skill-dir> && <command>"` (via library implementation)
- NFS mount at `~/mnt` shared across m3, m4, mbp ensures consistent paths
- Examples: `app-obsidian` (vaults on m3), `www-claude-usage` (Playwright browsers on m3)

**Library implementation:** Host detection belongs in library code (not CLI wrapper) so programmatic consumers also connect correctly:
```typescript
import { hostname } from 'os';
const currentHost = hostname().split('.')[0]; // m3.local → m3
if (currentHost !== TARGET_HOST) { /* SSH or throw */ }
```
- Common bug: `os.hostname()` returns FQDN (`m3.local`), always split on `.` and take `[0]`.

## Bundled Resources Details
### scripts/
Executable code (Python/Bash/etc.) for tasks requiring deterministic reliability or repeatedly rewritten.
- **When to include**: Same code being rewritten repeatedly or deterministic reliability needed
- **Benefits**: Token efficient, deterministic, may be executed without loading into context
- **Naming conventions:**
  - User-facing (>4 chars): `#` prefix (e.g., `#airtable`), use subcommand pattern for related scripts
  - Agent-facing: `_SKILL-NAME_action` pattern (e.g., `_EDIT-SKILL_package`)
  - All scripts: Must support `--help`, have proper error handling, be executable with shebang
- **src/+test/+scripts/ pattern**: Use when lots of shared logic OR importable API needed. Required for use-* and ops-* skills in TypeScript.

### references/
Documentation loaded as needed into context.
- **When to include**: Documentation Claude should reference while working (API docs, schemas, policies)
- **Benefits**: Keeps SKILL.md lean, loaded only when needed
- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md
- **Avoid duplication**: Info lives in SKILL.md OR references, not both

### assets/
Files used in output, not loaded into context.
- **When to include**: Files used in final output (templates, images, fonts, boilerplate)
- **Benefits**: Separates output resources from documentation

## Process for Editing Skills
1. Understand existing structure
2. Make effective edits (writing style, content placement)
3. Generate and verify CLAUDE.md pattern (requiredSkills in frontmatter, body auto-generated by `rp CLAUDE.md`)
4. Test scripts
5. Audit with $mdr:audit-skill (pass P0/P1/P2 + important P3s)

### 1. Understanding Existing Structure
Before editing, understand the skill's current structure:
1. Read SKILL.md to understand purpose and current workflow
2. Check what bundled resources exist (scripts/, references/, assets/)
3. Understand dependencies on other skills or external services
4. Review recent changes (if available) to understand evolution

### 2. Making Effective Edits
For documentation style rules (DRY, structure, succinctness), see `$interface-system/references/file-editing-policies/`.

**What does NOT belong in SKILL.md:**
- Complete implementation examples (>20 lines of code)
- Framework-specific integration patterns
- Full workflow implementations
- (DO include: API signatures, function definitions, brief usage snippets 1-3 lines)

**Key Questions to Answer in SKILL.md:**
1. What is the purpose of the skill?
2. When should the skill be used?
3. How should Claude use the skill? Reference all reusable contents.

### 3. Generate CLAUDE.md
Use `rp init` to generate CLAUDE.md then use `rp add` to edit its `requiredSkills` and `requiredFiles`. 

See `$cli-repomix` for more details.

### 4. Validation Workflow
1. **Make edits** to SKILL.md or bundled resources
2. **Launch audit subagent**: Load `$mdr:audit-skill` (pass P0/P1/P2 + important P3s)
3. **Address findings** and repeat until passing

### 5. Testing Script Changes
1. Run `ccsync` then verify symlink exists and points to correct location in `scripts/`
2. Test script execution with --help flag
3. Test script with realistic inputs (dry-run if destructive)
4. Validate against standards: Load `$mdr:audit-scripts`

### 6. Audit with `$mdr:audit-skill`

## $edit-skill Scripts
All scripts are globally available in `~/mnt/.bin/`:

| Script | Purpose |
|--------|---------|
| `_EDIT-SKILL_package` | Create distributable zip file after validation |
| `ccsync` | Sync all skill resources (scripts + commands) to their destinations |

### ccsync
Syncs skill resources to central locations:
- **Scripts** (`scripts/*`) → `~/mnt/.bin/`
- **Commands** (`commands/*.md`) → `~/mnt/mdr/commands/`
- **Workflows** (`commands/N-*.md`) → `~/mnt/mdr/commands/workflows/`

Files in `commands/` starting with `digit-` (e.g., `5-email-triage.md`) route to workflows; others route to commands.

```bash
ccsync                    # Sync all resources
ccsync <skill-name>       # Sync specific skill only
ccsync --list             # Show all resources and status
ccsync --dry-run          # Preview what would be synced
```

================
File: lib-1password/SKILL.md
================
---
name: lib-1password
description: >-
  1Password CLI setup for secrets management. Covers vendored binaries, service account authentication, and migrating hardcoded secrets to 1Password.
---

# 1Password CLI (op) - Secrets Management

## TABLE OF CONTENTS
1. Current Setup
2. Vendored Binaries
3. Authentication
  - Service Account (Headless)
  - Interactive (Touch ID)
4. Reading Secrets
  - Single Value
  - All Fields (One Call)
  - Environment Injection
5. Migrating Hardcoded Secrets
  - Preferred Pattern: Template + Lazy Inject
6. Troubleshooting

## Current Setup
**Already installed.** Configuration lives in:

| Component | Location |
|-----------|----------|
| `OP_SERVICE_ACCOUNT_TOKEN` | `~/.dispatch/once` |
| `$OP` (binary path) | `~/.dispatch/once` |
| `_LIB-1PASSWORD_print-secrets` | `~/.bin/vendor/op/` |
| `op()` function | `~/.dispatch/interactive_aliases` |
| Vendored binaries | `~/.bin/vendor/op/` |

Verify: `op whoami`

## Vendored Binaries
**Note:** `scripts/` symlinks to `~/.bin/vendor/op/` (vendored directory).

```
~/.bin/vendor/op/
  _LIB-1PASSWORD_print-secrets # Print secrets as export statements
  install.sh            # Downloads binaries (already run)
  op-darwin_amd64       # macOS Intel
  op-darwin_arm64       # macOS Apple Silicon
  op-linux_amd64        # Linux x86_64
  op-linux_arm64        # Linux arm64
```

**Why vendored?** No PATH pollution, works offline, deterministic across machines.

**Shell integration pattern:**
```bash
# ~/.dispatch/once — sets $OP based on platform
case "$(uname -s)/$(uname -m)" in
  Darwin/arm64)  OP="$HOME/.bin/vendor/op/op-darwin_arm64" ;;
  Darwin/x86_64) OP="$HOME/.bin/vendor/op/op-darwin_amd64" ;;
  Linux/aarch64) OP="$HOME/.bin/vendor/op/op-linux_arm64" ;;
  Linux/x86_64)  OP="$HOME/.bin/vendor/op/op-linux_amd64" ;;
esac
export OP

# ~/.dispatch/interactive_aliases — wrapper function
op() { "$OP" "$@"; }
```

## Authentication
### Service Account (Headless)
For scripts, CI, and avoiding per-session `op signin`:
```bash
export OP_SERVICE_ACCOUNT_TOKEN="ops_eyJ..."
```

**Setup:**
1. Go to 1password.com → Developer → Service Accounts
2. Create account, grant access to specific vault(s)
3. Copy token, add to `.dispatch/once` (before any `op` calls)

**Security:** Service accounts are scoped to specific vaults. Create a dedicated vault for CLI-accessible secrets.

### Interactive (Touch ID)
For one-off commands without service account:
```bash
eval $(op signin)
op whoami
```
Session expires after inactivity. Each tmux pane needs its own signin (session token is per-shell).

## Reading Secrets
### Single Value
```bash
op read "op://VaultName/ItemName/FieldName"
```

### All Fields (One Call)
Store related secrets in one item, read all at once (~2s total vs ~2s per field):
```bash
# Create item with multiple fields
op item create --vault wsh --category "Secure Note" --title "home" \
  AWS_KEY="AKIA..." \
  AWS_SECRET="..." \
  GITHUB_TOKEN="ghp_..."
```

Use `_LIB-1PASSWORD_print-secrets` to print as export statements:
```bash
_LIB-1PASSWORD_print-secrets                # All items (with # headers)
_LIB-1PASSWORD_print-secrets home           # Single item (no header)
eval "$(_LIB-1PASSWORD_print-secrets home)" # Export
```

Run with `--help` for full usage.

### Environment Injection
**`op run`** — inject secrets for subprocess only:
```bash
# .env.op (safe to commit - just references)
MY_API_KEY="op://wsh/home/API_KEY"

# Secrets available only during command execution
op run --env-file=.env.op -- ./deploy.sh
```

**`op inject`** — generate file with real values:
```bash
# Template → output (cache locally, gitignore output)
op inject -i .env.template -o .env
source .env
```

**Caching pattern for shell startup:**
```bash
# In .bashrc - regenerate cache if missing or stale (>1 day)
SECRETS_CACHE=~/.cache/op-secrets.env
if [[ ! -f "$SECRETS_CACHE" ]] || [[ $(find "$SECRETS_CACHE" -mtime +1 2>/dev/null) ]]; then
  op inject -i ~/.dispatch/secrets.template -o "$SECRETS_CACHE" 2>/dev/null
fi
source "$SECRETS_CACHE" 2>/dev/null
```

## Migrating Hardcoded Secrets
**MUST read:** `$mdr:audit-scripts/references/script-development-guide.md` for wrapper best practices (naming, --help, error handling) when creating or updating skill scripts.

### Preferred Pattern: Template + Lazy Inject
For scripts that need secrets, use `op inject` to generate `.env` from a template on first run.

**Key principle:** Each secret lives in ONE 1Password item. Multiple apps can reference the same item. When rotating a secret, update only that one item.

**Directory structure:**
```
skill-name/
├── .env.template   # Committed - contains op:// references
├── .env            # Gitignored - generated with real values
├── .gitignore      # Must include .env
└── scripts/
    └── my-script   # Bash wrapper that sources ../.env
```

**Use standard names and location.** Always use `.env.template` and `.env` in the **project root** - never custom names (`.airtable.env`) or nested in scripts/. This ensures consistency across bash-only and TypeScript skills.

**1. Identify the secret owner:**
Secrets are named `skills_<owner-skill>`. The owner is the skill that provides the capability:
- `LITELLM_MASTER_KEY` → `skills_mon-litellm` (mon-litellm provides LiteLLM proxy access)
- `HACKMD_TOKEN` → `skills_query-hackmd`
- `ZOTERO_API_KEY` → `skills_app-zotero`

If the item doesn't exist, create it. **Always use `--category "Secure Note"`** (not Login or other types):
```bash
op item create --vault wsh --category "Secure Note" --title "skills_mon-litellm" \
  "LITELLM_MASTER_KEY=secret123"
```

**2. Create `.env.template` (committed):**
Reference the owner's item, not your own skill. **No quotes** - some parsers don't strip them:
```bash
# .env.template (in project root)
export LITELLM_MASTER_KEY=op://wsh/skills_mon-litellm/LITELLM_MASTER_KEY
```

**3. Add to `.gitignore`:**
```
.env
```

**4. Wrapper patterns (choose ONE based on project type):**

#### Pattern A: Bash + Python (no src/)
Wrapper loads .env and execs Python script:
```bash
#!/usr/bin/env bash
SCRIPT_DIR="$(dirname "$(readlink -f "$0")")"
ROOT_DIR="$(dirname "$SCRIPT_DIR")"
if [ ! -f "$ROOT_DIR/.env" ]; then
  op inject -i "$ROOT_DIR/.env.template" -o "$ROOT_DIR/.env"
fi
source "$ROOT_DIR/.env"
exec python "$SCRIPT_DIR/my-script.py" "$@"
```

#### Pattern B: TypeScript (CANONICAL - use lib-utils)
**Use `initEnv` from lib-utils.** This is the standard pattern for all TypeScript projects.

```bash
bun add github:wsh-auto/lib-utils
bun add file:../lib-log file:../lib-1password
```

Entry point (`src/index.ts`):
```typescript
import { createLogger } from '@mdr/lib-utils/logger';
import { initEnv } from '@mdr/lib-utils/env';

const log = createLogger('my-project');
initEnv(import.meta.dirname, ['MY_REQUIRED_VAR'], log);

// Application code - process.env is now populated
```

**Why lib-utils?**
- CI-safe: gracefully skips when lib-1password unavailable
- Handles op binary detection (vendored + PATH)
- Loads .env via dotenv automatically
- Consistent across all TypeScript projects

**5. Application code reads `process.env`, not files** - never parse .env directly.

See CONTRIBUTING.md for the full migration plan.

## Troubleshooting
**"command not found: op"**
- Ensure `$OP` is exported and `op()` function is defined
- Check binary exists: `ls -la ~/.bin/vendor/op/`

**"authorization prompt timeout"**
- Service account token not set, or expired
- Check: `echo $OP_SERVICE_ACCOUNT_TOKEN | head -c 20`

**"could not find item"**
- Wrong vault or item name
- List items: `op item list --vault wsh`

**"You are not currently signed in"**
- For interactive: `eval $(op signin)`
- For headless: set `OP_SERVICE_ACCOUNT_TOKEN`

**Slow shell startup**
- Use caching pattern (see "Environment Injection")
- Or lazy-load: only call `op` when secrets are first needed

================
File: lib-log/README.md
================
# @mdr/lib-log

Dual-output logging for TypeScript and Python: colored console + JSON to [Axiom](https://axiom.co) (1TB/month free tier).

## Usage

See [SKILL.md](SKILL.md) for full API documentation, CLI usage, and configuration.

## Installation

**lib-log is private.** Projects access it via lib-utils (CI-safe wrapper):

```bash
# Consumers install lib-utils (public) + lib-log (local)
bun add github:wsh-auto/lib-utils
bun add file:../lib-log

# Import from lib-utils
import { createLogger } from '@mdr/lib-utils/logger';
```

## Projects Using lib-log (via lib-utils)

All TypeScript projects migrated to import from `@mdr/lib-utils` on 2026-01-16.

### TypeScript (mdr:)

| Project | Grade | Logger Names |
|---------|:-----:|--------------|
| app-apple-notes | C | mdr:app-apple-notes |
| app-claude-projects | C | mdr:app-claude-projects:curator, :index-manager, :parent-detection, :summarize |
| app-obsidian | B | mdr:app-obsidian |
| app-podcasts | B | mdr:app-podcasts, :cli |
| app-upnote | C | mdr:app-upnote |
| app-zotero | B | mdr:app-zotero |
| chat-telegram | A | mdr:chat-telegram, :api, :daemon, :polling |
| cli-mdr | B | mdr:cli-mdr, :cli, :example, :getSkills, :litellm |
| cli-repomix | D | mdr:cli-repomix:cli, :library |
| cli-tt | A | mdr:cli-tt, :agents, :auth, :daemon, :daemon:auto-submit, :daemon:booting, :daemon:cleanup, :daemon:pool, :daemon:queue, :daemon:sync, :hooks, :pool, :queue, :spawn, :tmux, :windows |
| ddb | A | ddb, :cli, :daemon, :filesystem, :fuse, :gmail, :health, :import, :pull, :summarize |
| lib-ccd | - | *(excluded - pure parser)* |
| mon-langfuse | B | mdr:mon-langfuse |
| mon-litellm | B | mdr:mon-litellm, :api |
| mon-openwebui | C | mdr:mon-openwebui |
| ops-frontmatter | C | mdr:ops-frontmatter |
| ops-pm2 | B | mdr:ops-pm2:start, :stop, :restart, :doctor, :fleet, :health, :pm2 |
| ops-sysguard | A | mdr:ops-sysguard:actions, :daemon, :metrics, :monitor, :processes |
| ops-watch | A | mdr:ops-watch, :cli |
| query-airtable | A | mdr:query-airtable |
| query-book | B | mdr:query-book |
| query-googleapis | A | mdr:query-googleapis:auth, :batch, :calendar, :contacts, :docs, :drive, :mail, :sheets, :slides, :youtube |
| query-hackmd | B | mdr:query-hackmd |
| query-ibkr | A | mdr:query-ibkr, :cli |
| query-inbox | B | mdr:query-inbox:imap, :smtp, :summarize, :body-parser, :retry, :cli, :ddb, :decisions |
| query-llm | C | mdr:query-llm:cli, :config, :mcp |
| srv-mdr | B | mdr:srv-mdr, :config |
| www-browser | A | mdr:www-browser |
| www-claude-usage | C | mdr:www-claude-usage |

### TypeScript (wsh:)

| Project | Grade | Logger Names |
|---------|:-----:|--------------|
| frontend | B | wsh:frontend |
| srv-plans | B | wsh:srv-plans, :sling, :state, :watch, :ws |
| srv-wsh | F | wsh:srv-wsh, :detector, :master, :pool, :router, :telegram |

### Python

Python projects import directly from lib-log (no lib-utils wrapper yet):

| Project | Grade | Logger Names |
|---------|:-----:|--------------|
| app-photos | A | mdr:app-photos |
| dev-mcp-server | B | mdr:dev-mcp-server |
| edit-changelog | C | mdr:edit-changelog |
| ops-git | B | mdr:ops-git |
| query-youtube | D | query-youtube |
| workflow-project | D | mdr:workflow-project |

## Grading

Grades measure how easy it is to debug a project from [Axiom](https://axiom.co) alone.

| Grade | Axiom Debuggability |
|:-----:|---------------------|
| **A** | Full diagnosis from Axiom. Structured metadata on all calls, operations traced start-to-end, errors include full context. |
| **B** | Most operations traceable. Good metadata on key paths but some gaps (missing elapsed times, bare errors, some calls without context). |
| **C** | Axiom shows the project is alive but not what happened. Bare messages without structured data, or only errors logged. |
| **D** | Import exists, 1-3 bare log calls. Axiom barely registers the project. |
| **F** | No log calls found in source. Nothing in Axiom. |

## Policy

- **CLI user-facing output** (--help, status, JSON) uses `console`
- **Internal logging** uses lib-log via lib-utils

================
File: lib-log/SKILL.md
================
---
name: lib-log
description: >-
  Centralized cloud logging for TypeScript and Python projects using Axiom.
  Provides dual output: colored console + JSON to Axiom. Use when adding logging
  to any project or querying logs with the ax CLI.
requiredFiles:
  - README.md
---

# lib-log

Centralized logging using Axiom (1TB/month free). See @README.md for list of users.

## Consumer Matrix

| Consumer | Console | Axiom | Token |
|----------|:-------:|:-----:|-------|
| TypeScript (Node.js) | ✅ | ✅ | `AXIOM_TOKEN` (ingest-only) |
| Python | ✅ | ✅ | `AXIOM_TOKEN` (ingest-only) |
| Frontend (browser) | ✅ | ✅ | `AXIOM_TOKEN_FRONTEND` via `window.__WSH_CONFIG__` |
| `ax` CLI | - | ✅ | `AXIOM_TOKEN_QUERY` (query-only) |

## TypeScript (Node.js)

Servers, CLI tools, background services.

```bash
bun add github:wsh-auto/lib-log  # CI/CD compatible
```

```typescript
import { createLogger } from '@mdr/lib-log';

const log = createLogger('srv-wsh');

log.debug('Frame received', { size: 1024 });
log.info('Client connected', { clientId: 'abc123' });
log.warn('Rate limit approaching', { current: 95 });
log.error('Connection failed', { error: err.message });

// Explicit flush before exit (for short-lived scripts)
await log.flush();
```

**Naming convention:** Main logger must be named `log`.

**Token auto-loads** from NFS mount - no setup needed on machines sharing `~/mnt`.

**Shared Axiom client:** All loggers in a process share one Axiom client. Calling `flush()` on any logger drains all pending logs from all loggers. This matters for projects like cli-tt with 18+ subsystem loggers - one `flush()` call before exit is sufficient.

## Python

Scripts, services, automation.

```bash
# NFS-shared machines (m3, m4, mbp)
uv add "lib-log @ file:///Users/eshao/mnt/mdr/skills/lib-log"

# Or from GitHub (after pushing changes)
uv add git+https://github.com/wsh-auto/lib-log
```

```python
from lib_log import create_logger

log = create_logger('edit-changelog')

log.debug('Parsing file', {'path': 'CHANGELOG.yaml'})
log.info('Entry added', {'version': '1.2.0'})
log.warn('Deprecated field', {'field': 'author'})
log.error('Validation failed', {'errors': ['missing version']})
```

## Frontend (Browser)

Use `@mdr/lib-utils/browser` for CI-safe imports (graceful degradation when lib-log unavailable):

```typescript
import { createLogger } from '@mdr/lib-utils/browser';

const log = createLogger('wsh:frontend');

log.info('Page loaded');
log.error('API call failed', { status: 500 });
```

Token read from `window.__WSH_CONFIG__.axiomToken` (injected by srv-plans).

**Security:** Frontend uses ingest-only token (`AXIOM_TOKEN_FRONTEND`). If leaked, attacker can only write logs, not read them.

## CLI: `ax`

Project-aware log viewer. Auto-detects project from cwd. Supports APL passthrough with flag merging.

```bash
ax                                  # Recent logs for current project (catches subsystems)
ax projects                         # List all project names
ax -f                               # Stream logs in real-time
ax --level error                    # Filter by level
ax --start-time 2h --end-time 1h    # Time range
ax --project '*cli-tt*'             # All cli-tt subsystems (contains)
ax --project '*tty1*'               # Auto-routes to tty1-logs dataset
ax --dataset tty1-logs              # Explicit dataset override
ax --all                            # All projects
ax --json                           # JSON output (for agents)
ax --full                           # Don't truncate field values

# APL passthrough (flags merge with query)
ax "['wsh-logs'] | where message contains 'error'" --all
ax "['wsh-logs']" --level warn --limit 50 --all
```

**Glob patterns:** Use `*foo*` (contains) - most useful since logger names have org prefix (e.g., `mdr:cli-tt`). Also supports `foo*` (startswith), `*foo` (endswith).

**Field truncation:** By default, field values are truncated to 200 chars. Use `--full` for complete values.

**Output order:** Chronological (oldest first, newest last) for both human and `--json` output.

Run `ax --help` for full usage.

## Configuration

**Token auto-loads** from `~/mnt/mdr/skills/lib-log/.env` (NFS mount, shared across machines).

**Graceful degradation:** If no token found, logs to console only (no errors).

### Tokens (1Password: `wsh/skills_lib-log`)

| Variable | Permissions | Used By |
|----------|-------------|---------|
| `AXIOM_TOKEN` | Ingest only | Node.js, Python |
| `AXIOM_TOKEN_FRONTEND` | Ingest only | Browser (via `__WSH_CONFIG__`) |
| `AXIOM_TOKEN_QUERY` | Query only | `ax` CLI |

**Why 3 tokens?** Principle of least privilege. If frontend token leaks, revoke it without affecting servers. Query token can't write spam.

### Other Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `AXIOM_DATASET` | `wsh-logs` | Dataset name |
| `LOG_LEVEL` | `debug` | Console minimum level: debug, info, warn, error. Axiom always receives all levels. |

**Runtime config (TypeScript):**
```typescript
const log = createLogger('my-project', {
  level: LogLevel.DEBUG,
  axiom: { enabled: false },  // Force console-only
});
```

## Output Format

**Console - TypeScript** (colored, no timestamp):
```
info - Client connected {"clientId":"abc123"}
```

**Console - Python** (colored, with timestamp):
```
2026-01-15 10:23:45 [srv-wsh] INFO  Client connected  clientId=abc123
```

**Axiom** (8-column schema):
```json
{
  "_time": "2026-01-15T10:23:45Z",
  "level": "info",
  "message": "Client connected",
  "project": "srv-wsh",
  "env": "production",
  "hostname": "m3",
  "context": "{\"clientId\":\"abc123\"}",
  "error": null
}
```

| Column | Type | Purpose |
|--------|------|---------|
| `_time` | timestamp | Time index (Axiom auto) |
| `level` | string | Filter errors/warns |
| `message` | string | Full-text search |
| `project` | string | Filter by project |
| `env` | string | Filter prod vs test |
| `hostname` | string | Filter by machine |
| `context` | JSON string | Arbitrary fields (clientId, taskId, etc.) |
| `error` | JSON string | Serialized Error object (null if no error) |

## Auto-Detected Fields

Every log entry includes these auto-detected fields:

| Field | Value | Example |
|-------|-------|---------|
| `project` | Logger name | `srv-wsh` |
| `env` | `test` if `BUN_TEST` or `NODE_ENV=test`, else `NODE_ENV` or `production` | `production` |
| `hostname` | Short hostname (`os.hostname().split('.')[0]`) or `browser` | `m3` |

**Filtering in Axiom (APL):**
```apl
| where env != 'test'                           # Production logs
| where project == 'srv-wsh'                    # By project
| where hostname == 'm3'                        # By machine
| extend ctx = parse_json(context)              # Access arbitrary fields
| where ctx.clientId == 'abc123'
```

## Project Naming Convention

Format: `{org}:{project}[:{subsystem}]`

| Example | Use Case |
|---------|----------|
| `wsh:srv-plans` | Main server code |
| `wsh:srv-plans:ws` | WebSocket handling subsystem |
| `mdr:cli-tt` | CLI tool |
| `wsh:frontend` | Browser app (Axiom via lib-utils/browser) |

**Rule:** Logger name must match where code lives. If `mdr:query-gmail` has no `query-gmail/src/`, don't use that logger name - the code is in `query-googleapis/src/lib/mail.ts`, so use `mdr:query-googleapis:mail`.

## Project Status

Project adoption status and intentional exclusions are tracked in this project's [README.md](README.md).

## Logging Large Values

lib-log does NOT truncate at write time - full values go to Axiom. Log content freely unless it would exceed 100KB/10s (either one big write or many small ones).

```typescript
// OK - error responses are typically small and infrequent
log.error('API failed', { status: 500, body: errorText });

// BAD - logging full HTML on every request
log.debug('Response', { html: page.content() });  // 10KB × 10 req/10s = 100KB/10s

// GOOD - truncate high-volume or large fields
log.debug('Response', { htmlPreview: page.content().slice(0, 500) });
```

The `ax` CLI truncates fields to 200 chars at read time to prevent agent freezes. Use `ax --full` when debugging.

## Error Logging

Pass Error objects directly - lib-log auto-serializes name, message, stack, and code to a separate `error` column:

```typescript
try {
  await operation();
} catch (err) {
  log.error('Operation failed', { error: err });  // Full serialization
}
```

**What gets captured:**
- `error.name` - Error class (TypeError, Error, custom)
- `error.message` - Error message
- `error.stack` - Full stack trace
- `error.code` - Node.js error codes (ENOENT, ETIMEDOUT)
- `error.cause` - Chained errors (ES2022)
- Any custom properties on the Error

**Any key name works** - lib-log scans all field values for `instanceof Error`:
```typescript
log.error('Failed', { err: myError });      // Works
log.error('Failed', { exception: myError }); // Works
log.error('Failed', { e: myError });         // Works
```

**Querying errors in Axiom:**
```apl
| where error != null
| extend err = parse_json(error)
| where err.code == 'ETIMEDOUT'
```

## Agent Guidelines

**Triggering logs to verify integration:** NEVER create test scripts. Instead:
1. Run existing tests (`bun run test`, `pytest`)
2. Run CLI commands with valid or invalid args to trigger error paths
3. Call existing functionality that has logging

If no existing code path emits logs, the project needs lib-log integration first.

================
File: lib-utils/scripts/_LIB-UTILS_update-dependents
================
#!/usr/bin/env bash
# Update all projects that depend on @mdr/lib-utils to latest version

set -uo pipefail  # Removed -e to not exit on errors

CYAN=$'\x1b[1m\x1b[36m'
YELLOW=$'\x1b[33m'
GREEN=$'\x1b[32m'
RED=$'\x1b[31m'
DIM=$'\x1b[2m'
BOLD=$'\x1b[1m'
NC=$'\x1b[0m'

show_help() {
  cat <<EOF

${CYAN}NAME${NC}
    ${BOLD}_LIB-UTILS_update-dependents${NC} - Update all lib-utils dependents to latest

${CYAN}USAGE${NC}
    ${BOLD}_LIB-UTILS_update-dependents${NC} [${YELLOW}OPTIONS${NC}]

${CYAN}DESCRIPTION${NC}
    Scans ~/mnt for all package.json files containing @mdr/lib-utils,
    removes their bun.lockb to clear pinned commits, and runs bun install
    to fetch the latest version from GitHub. Runs in parallel (8 jobs).

    ${DIM}Handles monorepo workspaces: if a package is inside a workspace,
    updates the workspace root instead (where bun.lockb lives).${NC}

${CYAN}OPTIONS${NC}
    ${YELLOW}--clean${NC}           Also remove node_modules (including workspace subdirs)
    ${YELLOW}--dry-run${NC}         List projects without updating
    ${YELLOW}--serial${NC}          Run sequentially instead of parallel
    ${YELLOW}--help${NC}, ${YELLOW}-h${NC}       Show this help message

${CYAN}EXAMPLES${NC}
    ${DIM}# Update all dependents (parallel)${NC}
    _LIB-UTILS_update-dependents

    ${DIM}# Preview what would be updated${NC}
    _LIB-UTILS_update-dependents --dry-run

${DIM}AGENTS: MUST load \$mdr:lib-utils before editing or for context${NC}
EOF
}

CLEAN=false
DRY_RUN=false
PARALLEL=true
MAX_JOBS=8

for arg in "$@"; do
  case $arg in
    --help|-h) show_help; exit 0 ;;
    --clean) CLEAN=true ;;
    --dry-run) DRY_RUN=true ;;
    --serial) PARALLEL=false ;;
    *) echo "Unknown option: $arg"; show_help; exit 1 ;;
  esac
done

echo "${CYAN}Scanning ~/mnt for @mdr/lib-utils dependents...${NC}"

# Find workspace root (parent with "workspaces" in package.json), or return original dir
find_workspace_root() {
  local dir=$1
  local current=$dir
  while [[ "$current" != "/" && "$current" != "$HOME" ]]; do
    local parent
    parent=$(dirname "$current")
    if [[ -f "$parent/package.json" ]] && grep -q '"workspaces"' "$parent/package.json" 2>/dev/null; then
      echo "$parent"
      return
    fi
    current=$parent
  done
  echo "$dir"  # Not in a workspace, return original
}

# Find all package.json with lib-utils, resolve to workspace roots, deduplicate
mapfile -t DEPENDENTS < <(
  rg -l '@mdr/lib-utils' ~/mnt --glob '**/package.json' --glob '!**/node_modules/**' --no-ignore --no-messages | \
  xargs -I{} dirname {} | \
  while read -r dir; do find_workspace_root "$dir"; done | \
  sort -u
)

if [[ ${#DEPENDENTS[@]} -eq 0 ]]; then
  echo "${YELLOW}No dependents found.${NC}"
  exit 0
fi

echo "Found ${GREEN}${#DEPENDENTS[@]}${NC} projects:"
echo

if $DRY_RUN; then
  for dir in "${DEPENDENTS[@]}"; do
    echo "  ${DIM}${dir/#$HOME/\~}${NC}"
  done
  echo
  echo "${YELLOW}Dry run - no changes made.${NC}"
  exit 0
fi

# Simple failure counter using a file
FAIL_FILE=$(mktemp)
echo 0 > "$FAIL_FILE"
trap 'rm -f "$FAIL_FILE"' EXIT

update_project() {
  local dir=$1
  local short_path="${dir/#$HOME/\~}"

  cd "$dir" || { printf "  \x1b[31m✗\x1b[0m %s \x1b[2mcd failed\x1b[0m\n" "$short_path"; return 1; }
  rm -f bun.lockb
  if [[ "$CLEAN" == "true" ]]; then
    rm -rf node_modules
    # Also clean workspace subdirectory node_modules (monorepo support)
    if [[ -f package.json ]] && grep -q '"workspaces"' package.json 2>/dev/null; then
      for ws in $(jq -r '.workspaces[]? // empty' package.json 2>/dev/null); do
        rm -rf "$ws/node_modules" 2>/dev/null
      done
    fi
  fi

  local output exit_code
  output=$(bun install 2>&1) && exit_code=0 || exit_code=$?

  if [[ $exit_code -eq 0 ]]; then
    local version
    version=$(echo "$output" | grep -o '@mdr/lib-utils@github:wsh-auto/lib-utils#[a-f0-9]*' | head -1 | sed 's/.*#//' | cut -c1-7)
    printf "  \x1b[32m✓\x1b[0m %s \x1b[2m%s\x1b[0m\n" "$short_path" "${version:-ok}"
    return 0
  else
    local err_msg
    err_msg=$(echo "$output" | grep -i -E 'error|fail' | head -1 | cut -c1-50)
    printf "  \x1b[31m✗\x1b[0m %s \x1b[2m%s\x1b[0m\n" "$short_path" "${err_msg:-failed}"
    return 1
  fi
}

export -f update_project
export HOME CLEAN

FAIL=0
if $PARALLEL; then
  pids=()
  for dir in "${DEPENDENTS[@]}"; do
    update_project "$dir" &
    pids+=($!)
    if [[ ${#pids[@]} -ge $MAX_JOBS ]]; then
      wait "${pids[0]}" || ((FAIL++)) || true
      pids=("${pids[@]:1}")
    fi
  done
  for pid in "${pids[@]}"; do
    wait "$pid" || ((FAIL++)) || true
  done
else
  for dir in "${DEPENDENTS[@]}"; do
    update_project "$dir" || ((FAIL++)) || true
  done
fi

SUCCESS=$((${#DEPENDENTS[@]} - FAIL))

echo
echo "${CYAN}Done:${NC} ${GREEN}${SUCCESS} updated${NC}$( [[ $FAIL -gt 0 ]] && echo ", ${RED}${FAIL} failed${NC}" )"
exit $([[ $FAIL -gt 0 ]] && echo 1 || echo 0)

================
File: lib-utils/src/env.ts
================
/**
 * Environment initialization wrapper for lib-1password.
 *
 * lib-1password is an optional dependency that may not be installed in CI.
 * This wrapper provides graceful degradation:
 * - Development: delegates to lib-1password for 1Password injection
 * - CI: returns empty stub (no secrets needed in CI)
 * - Missing dep outside CI: fatal error (forces proper setup)
 */

import type { DotenvConfigOutput } from 'dotenv';

/** Logger interface - console and lib-log Logger both satisfy this */
interface Log {
  info(msg: string, ...args: unknown[]): void;
  error(msg: string, ...args: unknown[]): void;
}

// Type matches lib-1password's initEnv signature
type InitEnvFn = (root: string, skip: string[], log: Log) => DotenvConfigOutput;

// Try to load lib-1password at module init. Will be either:
// - The real lib-1password module (normal case)
// - A stub that returns empty parsed object (CI case)
// - Never assigned (non-CI failure → process.exit before reaching here)
let lib1p: { initEnv: InitEnvFn };
try {
  lib1p = await import('@mdr/lib-1password');
} catch {
  const caller = process.argv[1] || 'unknown';
  if (process.env.CI) {
    // CI: lib-1password not needed, use stub that returns empty result
    console.log(`[lib-utils] lib-1password not available, using stub (caller: ${caller})`);
    lib1p = { initEnv: () => ({ parsed: {} }) };
  } else {
    // Development: lib-1password is required, fail loudly
    console.error(
      `[lib-utils] FATAL: lib-1password not available.\n` +
        `Add to optionalDependencies:\n` +
        `  "@mdr/lib-1password": "file:../lib-1password"\n` +
        `Then run: bun install\n` +
        `(caller: ${caller})`
    );
    process.exit(1);
  }
}

/**
 * Initialize environment from .env.template using 1Password CLI.
 * Safe to use in CI environments where lib-1password may not be installed.
 *
 * @param projectRoot - Directory containing .env.template and .env
 * @param skipIfEnvVars - Skip injection if ALL these env vars are already set
 * @param log - Logger with info/error methods (defaults to console)
 * @returns { parsed: Record<string, string> } - The loaded/skipped env vars
 */
export function initEnv(projectRoot: string, skipIfEnvVars: string[] = [], log: Log = console): DotenvConfigOutput {
  return lib1p.initEnv(projectRoot, skipIfEnvVars, log);
}

================
File: lib-utils/src/logger.ts
================
/**
 * Logger wrapper for lib-log.
 *
 * lib-log is an optional dependency that may not be installed in CI.
 * This wrapper provides graceful degradation:
 * - Development: full Axiom logging via lib-log
 * - CI: console-based stub logger
 * - Missing dep outside CI: fatal error (forces proper setup)
 */

interface Logger {
  debug(message: string, fields?: Record<string, unknown>): void;
  info(message: string, fields?: Record<string, unknown>): void;
  warn(message: string, fields?: Record<string, unknown>): void;
  error(message: string, fields?: Record<string, unknown>): void;
  child(fields: Record<string, unknown>): Logger;
  flush(): Promise<void>;
}

// Type matches lib-log's createLogger signature
type CreateLoggerFn = (name: string) => Logger;

/** Create a console-based stub logger for CI environments */
function _createStubLogger(name: string, parentFields: Record<string, unknown> = {}): Logger {
  const format = (level: string, message: string, fields?: Record<string, unknown>) => {
    const allFields = { ...parentFields, ...fields };
    const fieldsStr = Object.keys(allFields).length > 0 ? ` ${JSON.stringify(allFields)}` : '';
    return `${level} - [${name}] ${message}${fieldsStr}`;
  };

  return {
    debug: (msg, fields) => console.log(format('debug', msg, fields)),
    info: (msg, fields) => console.log(format('info', msg, fields)),
    warn: (msg, fields) => console.warn(format('warn', msg, fields)),
    error: (msg, fields) => console.error(format('error', msg, fields)),
    child: (fields) => _createStubLogger(name, { ...parentFields, ...fields }),
    flush: async () => {},
  };
}

// Try to load lib-log at module init. Will be either:
// - The real lib-log module (normal case)
// - A stub creator function (CI case)
// - Never assigned (non-CI failure → process.exit before reaching here)
let libLog: { createLogger: CreateLoggerFn; shutdown?: () => Promise<void> };
try {
  libLog = await import('@mdr/lib-log');
} catch {
  const caller = process.argv[1] || 'unknown';
  if (process.env.CI) {
    // CI: lib-log not needed, use console-based stub
    console.log(`[lib-utils] lib-log not available, using stub (caller: ${caller})`);
    libLog = { createLogger: _createStubLogger };
  } else {
    // Development: lib-log is required, fail loudly
    console.error(
      `[lib-utils] FATAL: lib-log not available.\n` +
        `Add to optionalDependencies:\n` +
        `  "@mdr/lib-log": "file:../lib-log"\n` +
        `Then run: bun install\n` +
        `(caller: ${caller})`
    );
    process.exit(1);
  }
}

/**
 * Create a logger that uses @mdr/lib-log if available, otherwise falls back to a stub.
 * Safe to use in CI environments where lib-log may not be installed.
 *
 * @param name - Logger name (appears in log output)
 * @returns Logger instance with debug/info/warn/error/child/flush methods
 */
export function createLogger(name: string): Logger {
  return libLog.createLogger(name);
}

/**
 * Flush all pending logs and reset the shared Axiom client.
 * Call in test teardown to allow clean process exit.
 */
export async function shutdown(): Promise<void> {
  if (libLog.shutdown) {
    await libLog.shutdown();
  }
}

================
File: lib-utils/CLAUDE.md
================
---
requiredSkills:
  - mdr:edit-skill
  - mdr:lib-1password
  - mdr:lib-log
requiredFiles:
  - scripts/_LIB-UTILS_update-dependents
  - src/env.ts
  - src/logger.ts
---

# lib-utils (13k)
## Documentation (2.4k)
- @SKILL.md (1.6k)
- @CONTRIBUTING.md (600)
- @package.json (300)

## Code (2.6k)
- @scripts/_LIB-UTILS_update-dependents (1.2k)
- @src/env.ts (600)
- @src/logger.ts (800)

## requiredSkills (8k)
- [@../edit-skill/SKILL.md (3k)](https://hackmd.io/TmfBsoskTnGqEf90YZch5Q)
- @../lib-1password/SKILL.md (2k)
- @../lib-log/SKILL.md (2k)
  - @../lib-log/README.md (1k)

================
File: lib-utils/CONTRIBUTING.md
================
# Development Guidelines for lib-utils

## Build Architecture

lib-utils has optional dependencies (`@mdr/lib-1password`, `@mdr/lib-log`) that don't exist in CI environments. This creates a TypeScript compilation challenge: the source files import these modules, but TypeScript can't resolve them.

**Solution:** Two-layer type system.

```
lib-utils/
├── src/
│   ├── env.ts          # await import('@mdr/lib-1password')
│   └── logger.ts       # await import('@mdr/lib-log')
├── stubs/              # Type stubs for optional deps (build-time)
│   ├── lib-1password.d.ts
│   └── lib-log.d.ts
└── dist/               # Generated .d.ts (consumer-facing)
    ├── env.d.ts
    └── logger.d.ts
```

### How It Works

1. **stubs/** - `declare module` statements that tell TypeScript "trust me, these modules export these types". Referenced via `paths` in tsconfig.build.json only.

2. **dist/** - Clean declaration files generated by `tsc`. These don't contain the problematic imports (TypeScript inlines the types).

3. **Consumers** import from `dist/*.d.ts` (via package.json `exports.types`), which `skipLibCheck: true` ignores.

### tsconfig Structure

**Critical:** Bun uses tsconfig.json `paths` for runtime module resolution, not just TypeScript compilation. Stubs must only be in build config.

| File | Purpose | Has paths? |
|------|---------|:----------:|
| `tsconfig.json` | Base config, used by Bun at runtime | ❌ |
| `tsconfig.build.json` | Generates `dist/*.d.ts` | ✅ |
| `tsconfig.check.json` | Typecheck validation | ✅ (extends build) |

| Command | Config | Emits |
|---------|--------|-------|
| `bun run build` | tsconfig.build.json | `dist/*.d.ts` |
| `bun run typecheck` | tsconfig.check.json | Nothing (validation only) |

### Important

- **Do not delete `stubs/`** - required for build to succeed
- **Do not delete `dist/`** - consumers need these declaration files
- **Do not add `paths` to tsconfig.json** - Bun resolves to stubs at runtime, breaking imports
- **Commit `dist/`** - consumers install via `github:`, no build step on install
- After modifying source, run `bun run build` to regenerate `dist/`

================
File: lib-utils/package.json
================
{
  "name": "@mdr/lib-utils",
  "version": "1.0.1",
  "type": "module",
  "packageManager": "bun@1.1.45",
  "typesVersions": {
    "*": {
      "logger": ["dist/logger.d.ts"],
      "env": ["dist/env.d.ts"],
      "browser": ["dist/browser-logger.d.ts"]
    }
  },
  "exports": {
    "./logger": {
      "types": "./dist/logger.d.ts",
      "default": "./src/logger.ts"
    },
    "./env": {
      "types": "./dist/env.d.ts",
      "default": "./src/env.ts"
    },
    "./browser": {
      "types": "./dist/browser-logger.d.ts",
      "default": "./src/browser-logger.ts"
    }
  },
  "scripts": {
    "build": "tsc -p tsconfig.build.json",
    "typecheck": "tsc -p tsconfig.check.json",
    "check": "bun run typecheck",
    "lint": "eslint '{src,test}/**/*.ts'",
    "lint:fix": "eslint '{src,test}/**/*.ts' --fix"
  },
  "devDependencies": {
    "@eslint/js": "8.57.0",
    "@mdr/dev-typescript": "link:@mdr/dev-typescript",
    "@types/node": "20.13.0",
    "dotenv": "^17.2.3",
    "eslint": "8.57.0",
    "typescript": "5.4.5",
    "typescript-eslint": "7.11.0"
  }
}

================
File: lib-utils/SKILL.md
================
---
name: lib-utils
description: >-
  CI-safe utilities for TypeScript projects. Provides logger wrapper (falls back to stub when lib-log unavailable) and env injection (skips in CI). Use for projects that need to work in both dev and CI without special setup.
---

# lib-utils

Utilities that enhance development but gracefully degrade in CI environments.

| Import Path | Optional Dep | With Dep | Without Dep (CI) | Without Dep (not CI) |
|-------------|--------------|----------|------------------|----------------------|
| `@mdr/lib-utils/logger` | lib-log | Axiom logging | Console stub | **exit(1)** |
| `@mdr/lib-utils/env` | lib-1password | 1Password injection | No-op stub | **exit(1)** |
| `@mdr/lib-utils/browser` | lib-log | Axiom logging | Console stub | Console stub |

## Installation

```bash
bun add github:wsh-auto/lib-utils
```

**Consumer `package.json` (only include optionalDeps you use):**
```json
"dependencies": {
  "@mdr/lib-utils": "github:wsh-auto/lib-utils"
},
"optionalDependencies": {
  "@mdr/lib-log": "link:@mdr/lib-log"
}
```

- **Separate exports**: Import from `/logger` or `/env` - each loads only its optional dep
- **lib-utils**: always `github:` in dependencies
- **lib-log/lib-1password**: always `link:` in **optionalDependencies** - only include what you use
- **CI**: graceful degradation (console stub / no-op)
- **Not CI**: fatal exit if optional dep missing for the export you import

**For 1Password env injection**, create `.env.template` (committed) with `op://` refs:
```bash
export MY_API_KEY=op://wsh/skills_my-project/API_KEY
```
Add `.env` to `.gitignore` - it's generated with real values at runtime.

## Logging
### lib-log / logger.ts - createLogger(project-name)

```typescript
import { createLogger } from '@mdr/lib-utils/logger';

const log = createLogger('my-project');

log.info('Starting');
log.error('Failed', { code: 500 });
await log.flush();
```

- If `@mdr/lib-log` installed: full Axiom logging
- If not + CI: console-based stub (debug/info/warn/error all log)
- If not + not CI: exit(1) with instructions to add to optionalDependencies

**CLI commands must `await shutdown()`** before exit - flushes pending logs AND releases the Axiom handle so the process exits cleanly. Without it, the Axiom connection keeps the event loop alive (~2s hang). Long-running daemons don't need `shutdown()`.

**`flush()` vs `shutdown()`:** `flush()` sends pending logs but keeps the Axiom handle open (useful mid-process). `shutdown()` flushes + sets the shared client to `undefined`, releasing the handle.

**Shared client:** All loggers share one Axiom client. One `shutdown()` call drains and closes all loggers in the process.

**Test teardown:** Call `await shutdown()` (not `flush()`) to close the Axiom client and allow vitest to exit cleanly.

**Output destinations:** With lib-log, logs go to both stderr (keeps stdout clean for pipeable data) and Axiom (cloud persistence). PM2 captures stderr but only shows info+ level - `log.debug()` entries are invisible in `pm2 logs` but ship to Axiom. When debugging, always use `ax` CLI over `pm2 logs` (see `$mdr:dev-debug`).

**CLI logging policy:**
- `stdout` - command output only (JSON, IDs, paths, tables)
- `stderr` - human status/progress (keep `stdout` pipeable)
- `--help`/`--version` - print and exit before initializing logging
- "CLI invoked" / argv dumps - `log.debug()` only, never on `--help`/`--version`, never include secrets
- If per-item status is already printed, log per-item at `debug` and keep `info` for summaries and durable side effects

**Required logging (add these to your code):**
- `log.info()` - MUST log: state changes (create/update/delete), external interactions (send email, API calls), recovery actions
- `log.warn()` - MUST log: degraded state, potential issues
- `log.error()` - MUST log: failures, exceptions
- `log.debug()` - SHOULD log: internal function calls useful for debugging (on by default, suppress with `LOG_LEVEL=info`)

**Don't log** high-volume operations at info level (>45/min: polling loops, health pings).

### Browser - createLogger(project-name)

For frontend/browser environments (e.g., React apps bundled with Vite):

```typescript
import { createLogger } from '@mdr/lib-utils/browser';

const log = createLogger('wsh:frontend');
log.info('Page loaded');
```

**Key differences from `/logger`:**
- No Node.js APIs (works in browsers)
- Never exits fatally - always graceful degradation
- Uses lazy initialization (no top-level await for Vite compatibility)

### Querying Logs: `ax` CLI

**Naming convention:** Logger name = folder name. If you're in `cli-tt/`, logs are at `--project cli-tt` (auto-catches subsystems like `cli-tt:daemon`, `cli-tt:pool`).

```bash
ax                          # Logs for current folder (auto-detects)
ax projects                 # List all project names
ax --project '*cli-tt*'     # All cli-tt subsystems (glob pattern)
ax --level error            # Filter by level
ax --json                   # JSON output for agents
```

**Glob patterns:** Use `*foo*` (contains) - most useful since logger names have org prefix (e.g., `mdr:cli-tt`).

See `$mdr:lib-log` for full ax documentation including APL passthrough.

## lib-1password / env.ts - initEnv(projectRoot, skipIfEnvVars?, log?)

```typescript
import { resolve } from 'path';
import { initEnv } from '@mdr/lib-utils/env';

// When .env.template is in same directory as calling file:
initEnv(import.meta.dirname);

// When .env.template is in parent directory (e.g., src/index.ts → project root):
initEnv(resolve(import.meta.dirname, '..'));              // CORRECT: canonical path
// initEnv(import.meta.dirname + '/..');                  // WRONG: leaves '..' unresolved

// Optional parameters:
initEnv(projectRoot, ['MY_API_KEY']);                     // skip if env vars already set
initEnv(projectRoot, [], customLogger);                   // custom logger (must have info/error)
```

- Returns `DotenvConfigOutput` with `{ parsed: Record<string, string> }`
- If `@mdr/lib-1password` installed: delegates to lib1p.initEnv() (1Password injection)
- If not + CI: returns `{ parsed: {} }` (empty stub)
- If not + not CI: exit(1) with instructions to add to optionalDependencies

## Scripts
`scripts/_LIB-UTILS_update-dependents` - Updates all lib-utils dependents. Run with `--help` for usage.





================================================================
End of Codebase
================================================================
